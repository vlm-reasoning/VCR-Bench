<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="description" content="VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning">
    <meta name="keywords" content="Video-CoT">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>VCR-Bench</title>

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="./static/css/leaderboard.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.27.0/gradio.js"></script>
  </head>

  <style>
    .expandable-card .card-text-container {
      max-height: 200px;
      overflow-y: hidden;
      position: relative;
    }

    .expandable-card.expanded .card-text-container {
      max-height: none;
    }

    .expand-btn {
      position: relative;
      display: none;
      background-color: rgba(255, 255, 255, 0.8);
      /* margin-top: -20px; */
      /* justify-content: center; */
      color: #510c75;
      border-color: transparent;
    }

    .expand-btn:hover {
      background-color: rgba(200, 200, 200, 0.8);
      text-decoration: none;
      border-color: transparent;
      color: #510c75;
    }

    .expand-btn:focus {
      outline: none;
      text-decoration: none;
    }

    .expandable-card:not(.expanded) .card-text-container:after {
      content: "";
      position: absolute;
      bottom: 0;
      left: 0;
      width: 100%;
      height: 90px;
      background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
    }

    .expandable-card:not(.expanded) .expand-btn {
      margin-top: -40px;
    }

    .card-body {
      padding-bottom: 5px;
    }

    .vertical-flex-layout {
      justify-content: center;
      align-items: center;
      height: 100%;
      display: flex;
      flex-direction: column;
      gap: 5px;
    }

    .figure-img {
      max-width: 100%;
      height: auto;
    }

    .adjustable-font-size {
      font-size: calc(0.5rem + 2vw);
    }

    .chat-history {
      flex-grow: 1;
      overflow-y: auto;
      /* overflow-x: hidden; */
      padding: 5px;
      border-bottom: 1px solid #ccc;
      margin-bottom: 10px;
    }

    #gradio pre {
      background-color: transparent;
    }
  </style>

  <body>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                VCR-Bench: A Comprehensive Evaluation
                <br>
                Framework for Video Chain-of-Thought Reasoning
              </h1>
             <br>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a style="font-weight:normal;">Yukun Qi<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Yiming Zhao<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Yu Zeng<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Xikun Bao<sup>1,2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Wenxuan Huang<sup>3</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://lin-chen.site/" style="font-weight:normal;">Lin Chen<sup>1*</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://lovesnowbest.site/" style="font-weight:normal;">Zehui Chen<sup>1</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Jie Zhao<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a style="font-weight:normal;">Zhongang Qi<sup>2</sup></a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.co.uk/citations?user=r6CvuOUAAAAJ&hl=en" style="font-weight:normal;">Feng Zhao<sup>1&dagger;</sup></a>,
                </span>

              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><b style="color:#00389A; font-weight:normal">&#x25B6 </b> <sup>1</sup> University of Science and Technology of China</span>
                <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> <sup>2</sup> Huawei Noah's Ark Lab</span>
                <br>
                <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> <sup>3</sup> East China Normal University</span>
              </div>
              
              <div class="is-size-6 publication-authors">
                <br>
                <span class="author-block"><b>*</b> Equal contribution.</span>
                <span class="author-block"><b>&dagger;</b> Corresponding authors.</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                    <span class="link-block">
                    <!-- TODO: change links -->
                      <a href="https://arxiv.org/pdf/2502.09621"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                    <span>Paper</span>
                    </a>
                  </span>
                  <!-- Paper Link.-->
                  <span class="link-block">
                    <a href="https://eccv.ecva.net/virtual/2024/poster/765" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arVix</span>
                    </a>
                  </span>
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/zhishuifeiqian/VCR-Bench" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- Dataset Link. -->
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/VLM-Reasoning/VCR-Bench"
                      class="external-link button is-normal is-rounded is-dark">
                      <span>ü§ó Dataset</span>
                    </a>
                  </span>
                  <!-- Leaderboard Link. -->
                  <span class="link-block">
                    <a href="https://vlm-reasoning.github.io/VCR-Bench/#leaderboard"
                      class="external-link button is-normal is-rounded is-dark">
                    <span>üèÜ Leaderboard</span>
                  </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section"  style="background-color:#efeff081" id="Abstract">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                The advancement of Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs) and large vision-language models (LVLMs).
                However, a rigorous evaluation framework for video CoT reasoning remains absent. Current video benchmarks fail to adequately assess the reasoning process and expose whether failures stem from deficiencies in perception or reasoning capabilities. 
                Therefore, we introduce <b>VCR-Bench</b>, a novel benchmark designed to comprehensively evaluate LVLMs' <b>V</b>ideo <b>C</b>hain-of-Thought <b>R</b>easoning capabilities. VCR-Bench comprises 859 videos spanning a variety of video content and durations, along with 1,034 high-quality question-answer pairs. 
                Each pair is manually annotated with a stepwise CoT rationale, where every step is tagged to indicate its association with the perception or reasoning capabilities. Furthermore,we design seven distinct task dimensions and propose the CoT score to assess the entire CoT process based on the stepwise tagged CoT rationals.
                Extensive experiments on VCR-Bench highlight substantial limitations in current LVLMs. Even the top-performing model, o1, only achieves a 62.8% CoT score and an 56.7% accuracy, while most models score below 40%. 
                Experiments show most models score lower on perception than reasoning steps, revealing LVLMs' key bottleneck in temporal-spatial information processing for complex video reasoning.
                A robust positive correlation between the CoT score and accuracy confirms the validity of our evaluation framework and underscores the critical role of CoT reasoning in solving complex video reasoning tasks. We hope VCR-Bench to serve as a standardized evaluation framework and expose the actual drawbacks in complex video reasoning.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    
    <section class="section">
      <div class="container">
        
        <div class="columns is-centered">
          <div class="column is-full has-text-centered content">
            <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
            <div class="content">
              <table class="js-sort-table" id="results">
                <thead>
                  <tr>
                    <th rowspan="1" style="vertical-align: middle;"><strong>#</strong></th>
                    <th rowspan="1" style="vertical-align: middle;"><strong>Model</strong></th>
                    <th><strong>FTR</strong></th>
                    <th><strong>VTC</strong></th>
                    <th><strong>VTG</strong></th>
                    <th><strong>VKR</strong></th>
                    <th><strong>TSR</strong></th>
                    <th><strong>VPA</strong></th>
                    <th><strong>TSG</strong></th>
                    <th><strong>Avg</strong></th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>1</td>
                    <td><b class="best-score-text">o1 ü•á</b></td>
                    <td><b>66.7</b></td>
                    <td><b>52.2</b></td>
                    <td><u>56.9</u></td>
                    <td><b>74.3</b></td>
                    <td><b>61.0</b></td>
                    <td><b>60.2</b></td>
                    <td>0.0</td>
                    <td><b>56.7</b></td>
                  </tr>
                  <tr>
                    <td>2</td>
                    <td><b class="best-score-text">Gemini-2.0-Flash ü•à</b></td>
                    <td><u>66.2</u></td>
                    <td><u>51.2</u></td>
                    <td><b>62.0</b></td>
                    <td>64.4</td>
                    <td><u>54.1</u></td>
                    <td><u>58.1</u></td>
                    <td><b>4.2</b></td>
                    <td><u>51.7</u></td>
                  </tr>
                  <tr>
                    <td>3</td>
                    <td><b class="best-score-text">GPT-4o ü•â</b></td>
                    <td>54.7</td>
                    <td>49.1</td>
                    <td>44.8</td>
                    <td><u>68.6</u></td>
                    <td>48.9</td>
                    <td>57.6</td>
                    <td><u>2.8</u></td>
                    <td>46.9</td>
                  </tr>
                  <tr>
                    <td>4</td>
                    <td><b>Gemini-1.5-Pro</b></td>
                    <td>55.1</td>
                    <td>45.3</td>
                    <td>52.9</td>
                    <td>62.0</td>
                    <td>45.0</td>
                    <td>45.6</td>
                    <td>0.7</td>
                    <td>44.0</td>
                  </tr> 
                  <tr>
                    <td>5</td>
                    <td><b>Claude 3.5 Sonnet</b></td>
                    <td>45.3</td>
                    <td>46.3</td>
                    <td>34.3</td>
                    <td>64.2</td>
                    <td>44.0</td>
                    <td>49.3</td>
                    <td>0.7</td>
                    <td>41.0</td>
                  </tr>
                  <tr>
                    <td>6</td>
                    <td><b>Aria-25B</b></td>
                    <td>45.3</td>
                    <td>45.0</td>
                    <td>33.6</td>
                    <td>56.2</td>
                    <td>43.7</td>
                    <td>38.8</td>
                    <td><u>2.8</u></td>
                    <td>38.2</td>
                  </tr>
                  <tr>
                    <td>7</td>
                    <td><b>Qwen2.5-VL-72B</b></td>
                    <td>45.0</td>
                    <td>39.9</td>
                    <td>34.1</td>
                    <td>56.2</td>
                    <td>38.1</td>
                    <td>48.9</td>
                    <td>2.1</td>
                    <td>37.9</td>
                  </tr>
                  <tr>
                    <td>8</td>
                    <td><b>LLaVA-Video-72B</b></td>
                    <td>49.7</td>
                    <td>49.1</td>
                    <td>17.5</td>
                    <td>49.7</td>
                    <td>43.7</td>
                    <td>43.2</td>
                    <td>2.1</td>
                    <td>36.6</td>
                  </tr>
                  <tr>
                    <td>9</td>
                    <td><b>LLaVA-OneVision-72B</b></td>
                    <td>47.8</td>
                    <td>42.2</td>
                    <td>25.9</td>
                    <td>52.3</td>
                    <td>45.9</td>
                    <td>38.1</td>
                    <td>0.0</td>
                    <td>36.4</td>
                  </tr>
                  <tr>
                    <td>10</td>
                    <td><b>InternVideo2.5-8B</b></td>
                    <td>40.9</td>
                    <td>43.5</td>
                    <td>14.0</td>
                    <td>42.1</td>
                    <td>48.1</td>
                    <td>41.7</td>
                    <td>0.0</td>
                    <td>33.0</td>
                  </tr>
                  <tr>
                    <td>11</td>
                    <td><b>LLaVA-Video-7B</b></td>
                    <td>47.2</td>
                    <td>36.6</td>
                    <td>18.9</td>
                    <td>41.8</td>
                    <td>40.7</td>
                    <td>40.3</td>
                    <td>0.0</td>
                    <td>32.5</td>
                  </tr>
                  <tr>
                    <td>12</td>
                    <td><b>VideoLLaMA3-7B</b></td>
                    <td>44.7</td>
                    <td>36.6</td>
                    <td>24.5</td>
                    <td>43.1</td>
                    <td>36.3</td>
                    <td>39.6</td>
                    <td>0.7</td>
                    <td>32.5</td>
                  </tr>
                  <tr>
                    <td>13</td>
                    <td><b>InternVL2.5-78B</b></td>
                    <td>40.9</td>
                    <td>39.8</td>
                    <td>9.8</td>
                    <td>52.9</td>
                    <td>29.6</td>
                    <td>39.6</td>
                    <td>0.0</td>
                    <td>30.9</td>
                  </tr>
                  <tr>
                    <td>14</td>
                    <td><b>LLaVA-OneVision-7B</b></td>
                    <td>35.8</td>
                    <td>34.8</td>
                    <td>24.5</td>
                    <td>39.9</td>
                    <td>37.8</td>
                    <td>41.0</td>
                    <td>0.0</td>
                    <td>30.7</td>
                  </tr>
                  <tr>
                    <td>15</td>
                    <td><b>Qwen2.5-VL-7B</b></td>
                    <td>37.1</td>
                    <td>26.7</td>
                    <td>29.4</td>
                    <td>47.1</td>
                    <td>34.8</td>
                    <td>36.0</td>
                    <td>0.7</td>
                    <td>30.4</td>
                  </tr>
                  <tr>
                    <td>16</td>
                    <td><b>MiniCPM-o2.6-8B</b></td>
                    <td>31.4</td>
                    <td>30.4</td>
                    <td>12.6</td>
                    <td>43.8</td>
                    <td>30.4</td>
                    <td>38.1</td>
                    <td>0.0</td>
                    <td>26.9</td>
                  </tr>
                  <tr>
                    <td>17</td>
                    <td><b>InternVL2.5-8B</b></td>
                    <td>32.7</td>
                    <td>29.8</td>
                    <td>11.9</td>
                    <td>33.3</td>
                    <td>25.9</td>
                    <td>30.9</td>
                    <td>0.7</td>
                    <td>23.9</td>
                  </tr>
                  <tr>
                    <td>18</td>
                    <td><b>mPLUG-Owl3-7B</b></td>
                    <td>13.2</td>
                    <td>6.2</td>
                    <td>2.8</td>
                    <td>5.9</td>
                    <td>15.6</td>
                    <td>7.2</td>
                    <td>0.0</td>
                    <td>7.3</td>
                  </tr>
                  <tr>
                    <td>19</td>
                    <td><b>Llama-3.2-11B-Vision</b></td>
                    <td>4.4</td>
                    <td>4.3</td>
                    <td>7.0</td>
                    <td>6.5</td>
                    <td>6.7</td>
                    <td>5.8</td>
                    <td>0.0</td>
                    <td>4.9</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- DATASET SECTION -->
    <section class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <!-- <h1 class="title is-1 mathvista"><img src="static/images/logo.png" style="width:1.0em;vertical-align: middle" alt="Logo"/>MathVista Dataset</h1> -->
      <h1 class="title is-1 mathvista">
        <span class="mathvista" style="vertical-align: middle">VCR-Bench Dataset</span>
      </h1>
      </div>
    </section>

    <section class="section">
      <div class="container">

      </div>
    </section>
  
  </body>

</html>